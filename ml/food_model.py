import torchvision.transforms as transforms
import torch
import torchvision.models as models
import os
import torch.nn as nn
from PIL import Image
from torch.utils.data import DataLoader, Dataset

from log.log_writer import log
from ml.data_loader import product_lists, product_classes_idx


class FoodDataset(Dataset):
    """–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ"""

    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
        self.class_to_idx = product_classes_idx

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        try:
            image = Image.open(self.image_paths[idx]).convert('RGB')
            label = self.class_to_idx.get(self.labels[idx], 5)  # '–¥—Ä—É–≥–æ–µ' –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

            if self.transform:
                image = self.transform(image)

            return image, label
        except Exception as e:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            image = Image.new('RGB', (224, 224), color='gray')
            if self.transform:
                image = self.transform(image)
            return image, 5  # –ö–ª–∞—Å—Å '–¥—Ä—É–≥–æ–µ'

class FoodModel:
    def __init__(self, food_classes = None):
        log('debug',"üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—É—á–∞–µ–º—É—é –º–æ–¥–µ–ª—å...")

        self.ml_dir = os.path.dirname(os.path.abspath(__file__))
        self.model_path = os.path.join(self.ml_dir, "trained_model.pth")

        # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        log('debug',f"üì± –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")

        # –ö–ª–∞—Å—Å—ã (—Å–æ–≤–ø–∞–¥–∞—é—Ç —Å DataCollector)
        self.class_names = product_lists
        self.class_to_idx = {name: i for i, name in enumerate(self.class_names)}

        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        self.train_transform = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomCrop((224,224)),
            transforms.RandomHorizontalFlip(),
            transforms.RandomRotation(25),
            transforms.ColorJitter(0.3, 0.3, 0.3, 0.1),
            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        self.val_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
        self.model = self._create_model()
        self.is_trained = False

        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        if os.path.exists(self.model_path):
            self.load_model()
            log('debug',"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")
        else:
            log('error',"üÜï –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞. –ù—É–∂–Ω–æ —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏ –æ–±—É—á–∏—Ç—å.")

    def _create_model(self):
        """–°–æ–∑–¥–∞—ë—Ç –º–æ–¥–µ–ª—å —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏"""
        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)
        for param in model.parameters():
            param.requires_grad = False

        num_features = model.classifier[1].in_features
        classes_amount = len(self.class_names)
        model.classifier[1] = nn.Linear(num_features, classes_amount)

        return model.to(self.device)

    def train(self, data_collector, epochs=5, batch_size=8):
        """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        log('debug',"üéØ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        labeled_data = data_collector.get_labeled_data()
        if len(labeled_data) < 10:
            log('error',f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(labeled_data)} –æ–±—Ä–∞–∑—Ü–æ–≤ (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 10)")
            return False
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –ø—É—Ç–∏ –∏ –º–µ—Ç–∫–∏
        image_paths, labels = zip(*labeled_data)
        # –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç –∏ –∑–∞–≥—Ä—É–∑—á–∏–∫
        dataset = FoodDataset(image_paths, labels, transform=self.train_transform)
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)
        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)
        criterion = nn.CrossEntropyLoss()

        # –û–±—É—á–µ–Ω–∏–µ
        self.model.train()
        for epoch in range(epochs):
            total_loss = 0
            correct = 0
            total = 0

            for images, labels in dataloader:
                images = images.to(self.device)
                labels = labels.to(self.device)

                optimizer.zero_grad()
                outputs = self.model(images)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                total_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

            accuracy = 100 * correct / total
            log('debug',
                f'üìä –≠–ø–æ—Ö–∞ [{epoch + 1}/{epochs}], Loss: {total_loss / len(dataloader):.4f}, Accuracy: {accuracy:.2f}%')

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        self.save_model()
        self.is_trained = True

        log('info',f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –û–±—É—á–µ–Ω–æ –Ω–∞ {len(labeled_data)} –æ–±—Ä–∞–∑—Ü–∞—Ö")
        return True

    def predict(self, image_path):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        if not self.is_trained:
            return {
                'success': False,
                'error': '–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞',
                'message': '–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'
            }

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = Image.open(image_path).convert('RGB')
            input_tensor = self.val_transform(image).unsqueeze(0).to(self.device)

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            self.model.eval()
            with torch.no_grad():
                outputs = self.model(input_tensor)
                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
                predicted_idx = torch.argmax(probabilities).item()
                confidence = probabilities[predicted_idx].item()

            predicted_class = self.class_names[predicted_idx]

            return {
                'success': True,
                'food_class': predicted_class,
                'confidence': round(confidence * 100, 2),
                'message': '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏',
                'all_probabilities': {
                    cls: round(prob.item() * 100, 2)
                    for cls, prob in zip(self.class_names, probabilities)
                }
            }

        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'message': '–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏'
            }

    def save_model(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'class_names': self.class_names,
            'is_trained': True
        }, self.model_path)
        log('info',f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {self.model_path}")

    def load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å"""
        try:
            checkpoint = torch.load(self.model_path, map_location=self.device)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.class_names = checkpoint.get('class_names', self.class_names)
            self.is_trained = checkpoint.get('is_trained', False)
            return True
        except Exception as e:
            log('error',f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False

    def get_model_info(self):
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
        return {
            'is_trained': self.is_trained,
            'model_path': self.model_path,
            'device': str(self.device),
            'class_names': self.class_names,
            'status': '–û–±—É—á–µ–Ω–∞' if self.is_trained else '–ù–µ –æ–±—É—á–µ–Ω–∞'
        }